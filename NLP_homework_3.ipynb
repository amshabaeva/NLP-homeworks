{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание по Автоматической обработке естественного языка №3\n",
    "\n",
    "### Настя Шабаева, БКЛ181\n",
    "\n",
    "### Установка SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.45.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.17.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (46.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.3.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/en_core_web_sm\n",
      "-->\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Импорт всего необходимого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Library/Frameworks/Pytho\n",
      "[nltk_data]     n.framework/Versions/3.7/lib/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import nltk; nltk.download('stopwords')\n",
    "from collections import Counter\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготавливаем стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Скачиваем днные в таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  target  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
       "\n",
       "            target_names  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# скачиваем данные\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка текста\n",
    "\n",
    "Тексты из таблица добавляем в список, убираем из них почтовые адреса, лишние кавычки, всякие символы типа переноса строк меняем на пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
      " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
      " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition, the front bumper was separate from the rest of the body. This is '\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
      " 'production, where this car is made, history, or whatever info you have on '\n",
      " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
      " 'your neighborhood Lerxst ---- ']\n"
     ]
    }
   ],
   "source": [
    "data = df.content.values.tolist() # тексты из датафрейма кладем в список\n",
    "\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data] # убираем почтовые адреса\n",
    "\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data] # меняем все пробельные символы (новая строка и тд) на пробелы\n",
    "\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]# убираем одинарные кавычки\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предложения -> слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляем биграммы и триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Функции, чтобы убрать стоп-слова, чтобы создать биграммы и триграммы, лемматизировать слова и оставить только существительные, прилагательные, глаголы и наречия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение описанных ранее функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['where', 'thing', 'car', 'nntp_poste', 'host', 'park', 'line', 'wonder', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'door', 'really', 'small', 'addition', 'separate', 'rest', 'body', 'know', 'model', 'name', 'engine', 'spec', 'year', 'production', 'car', 'make', 'history', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем словарь и корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 5), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1)]]\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "texts = data_lemmatized\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Обучаем модель (и печатаем топики, которые она выдаст)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.175*\"file\" + 0.073*\"entry\" + 0.057*\"error\" + 0.053*\"display\" + 0.040*\"program\" + 0.030*\"sun\" + 0.025*\"version\" + 0.024*\"cool\" + 0.020*\"output\" + 0.020*\"crash\"'),\n",
       " (1,\n",
       "  '0.032*\"would\" + 0.026*\"say\" + 0.022*\"think\" + 0.022*\"people\" + 0.020*\"go\" + 0.018*\"know\" + 0.016*\"make\" + 0.016*\"see\" + 0.014*\"come\" + 0.013*\"thing\"'),\n",
       " (2,\n",
       "  '0.091*\"evidence\" + 0.048*\"book\" + 0.041*\"faith\" + 0.037*\"reason\" + 0.033*\"exist\" + 0.032*\"claim\" + 0.031*\"religion\" + 0.029*\"believe\" + 0.027*\"christian\" + 0.023*\"church\"'),\n",
       " (3,\n",
       "  '0.541*\"ax\" + 0.054*\"car\" + 0.028*\"player\" + 0.014*\"engine\" + 0.009*\"dealer\" + 0.009*\"mile\" + 0.009*\"expensive\" + 0.009*\"here\" + 0.008*\"extra\" + 0.008*\"specify\"'),\n",
       " (4,\n",
       "  '0.087*\"belief\" + 0.084*\"internet\" + 0.079*\"atheist\" + 0.061*\"distribution\" + 0.053*\"wing\" + 0.041*\"atheism\" + 0.038*\"printer\" + 0.034*\"interface\" + 0.026*\"multiple\" + 0.020*\"thinking\"'),\n",
       " (5,\n",
       "  '0.088*\"normal\" + 0.072*\"port\" + 0.071*\"mouse\" + 0.053*\"hole\" + 0.036*\"cap\" + 0.034*\"expansion\" + 0.033*\"default\" + 0.026*\"compute\" + 0.026*\"noise\" + 0.013*\"characteristic\"'),\n",
       " (6,\n",
       "  '0.034*\"include\" + 0.023*\"provide\" + 0.023*\"report\" + 0.021*\"receive\" + 0.021*\"follow\" + 0.021*\"name\" + 0.018*\"build\" + 0.017*\"return\" + 0.015*\"open\" + 0.014*\"suggest\"'),\n",
       " (7,\n",
       "  '0.123*\"chip\" + 0.074*\"bit\" + 0.072*\"speed\" + 0.060*\"device\" + 0.058*\"tape\" + 0.052*\"slow\" + 0.040*\"bus\" + 0.038*\"scsi\" + 0.037*\"direct\" + 0.036*\"mode\"'),\n",
       " (8,\n",
       "  '0.152*\"team\" + 0.103*\"play\" + 0.059*\"year\" + 0.053*\"season\" + 0.045*\"fan\" + 0.036*\"trade\" + 0.026*\"pen\" + 0.023*\"lose\" + 0.021*\"last\" + 0.016*\"next\"'),\n",
       " (9,\n",
       "  '0.021*\"year\" + 0.016*\"also\" + 0.014*\"may\" + 0.014*\"first\" + 0.011*\"work\" + 0.010*\"high\" + 0.010*\"talk\" + 0.009*\"make\" + 0.009*\"case\" + 0.009*\"power\"'),\n",
       " (10,\n",
       "  '0.052*\"system\" + 0.050*\"drive\" + 0.041*\"use\" + 0.038*\"run\" + 0.034*\"problem\" + 0.028*\"window\" + 0.027*\"card\" + 0.024*\"program\" + 0.021*\"driver\" + 0.021*\"software\"'),\n",
       " (11,\n",
       "  '0.085*\"space\" + 0.053*\"science\" + 0.024*\"scientific\" + 0.024*\"review\" + 0.023*\"orbit\" + 0.023*\"launch\" + 0.022*\"earth\" + 0.021*\"mission\" + 0.020*\"development\" + 0.019*\"vehicle\"'),\n",
       " (12,\n",
       "  '0.140*\"game\" + 0.116*\"gun\" + 0.070*\"win\" + 0.048*\"fire\" + 0.047*\"hit\" + 0.036*\"weapon\" + 0.035*\"shoot\" + 0.024*\"cop\" + 0.019*\"run\" + 0.017*\"carry\"'),\n",
       " (13,\n",
       "  '0.124*\"god\" + 0.110*\"patient\" + 0.054*\"license\" + 0.050*\"univ\" + 0.048*\"treatment\" + 0.042*\"disease\" + 0.035*\"medical\" + 0.033*\"health\" + 0.027*\"ticket\" + 0.020*\"deliver\"'),\n",
       " (14,\n",
       "  '0.040*\"kill\" + 0.030*\"israeli\" + 0.028*\"war\" + 0.027*\"soldier\" + 0.024*\"attack\" + 0.024*\"village\" + 0.023*\"child\" + 0.021*\"murder\" + 0.016*\"turkish\" + 0.016*\"force\"'),\n",
       " (15,\n",
       "  '0.098*\"goal\" + 0.077*\"moral\" + 0.059*\"animal\" + 0.046*\"link\" + 0.034*\"morality\" + 0.029*\"warrant\" + 0.028*\"scale\" + 0.027*\"relationship\" + 0.026*\"depth\" + 0.024*\"percentage\"'),\n",
       " (16,\n",
       "  '0.049*\"image\" + 0.046*\"color\" + 0.040*\"code\" + 0.038*\"source\" + 0.038*\"com\" + 0.031*\"available\" + 0.030*\"server\" + 0.028*\"format\" + 0.026*\"function\" + 0.024*\"information\"'),\n",
       " (17,\n",
       "  '0.111*\"motif\" + 0.067*\"session\" + 0.048*\"unknown\" + 0.028*\"moslem\" + 0.021*\"ruin\" + 0.020*\"testing\" + 0.019*\"ratio\" + 0.017*\"okay\" + 0.005*\"verification\" + 0.005*\"automate\"'),\n",
       " (18,\n",
       "  '0.074*\"line\" + 0.047*\"write\" + 0.030*\"article\" + 0.024*\"host\" + 0.022*\"nntp_poste\" + 0.022*\"organization\" + 0.021*\"get\" + 0.019*\"be\" + 0.016*\"need\" + 0.014*\"thank\"'),\n",
       " (19,\n",
       "  '0.030*\"key\" + 0.027*\"state\" + 0.021*\"law\" + 0.020*\"government\" + 0.018*\"issue\" + 0.017*\"public\" + 0.014*\"right\" + 0.013*\"use\" + 0.011*\"system\" + 0.010*\"case\"')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет когерентности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.49288861569721343\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попытка установить mallet\n",
    "\n",
    "Неудачная, как выяснилось, из-за старой версии java на компьютере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '/Users/macbook/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /var/folders/ft/yj1cv23d74zgpvxgg4m_f5fc0000gp/T/e829b3_corpus.txt --output /var/folders/ft/yj1cv23d74zgpvxgg4m_f5fc0000gp/T/e829b3_corpus.mallet' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-d76e34847314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmallet_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/macbook/mallet-2.0.8/bin/mallet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mldamallet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold, random_seed)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \"\"\"\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' train-topics --input %s --num-topics %s  --alpha %s --optimize-interval %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;34m'--num-threads %s --output-state %s --output-doc-topics %s --output-topic-keys %s '\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[0;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '/Users/macbook/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /var/folders/ft/yj1cv23d74zgpvxgg4m_f5fc0000gp/T/e829b3_corpus.txt --output /var/folders/ft/yj1cv23d74zgpvxgg4m_f5fc0000gp/T/e829b3_corpus.mallet' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MALLET_HOME'] = '/Users/macbook/mallet-2.0.8/bin/'\n",
    "\n",
    "mallet_path = '/Users/macbook/mallet-2.0.8/bin/mallet'\n",
    "\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция, которая поможет определить оптимальное количество топиков\n",
    "\n",
    "Алгоритм: создать несколько моделей с разным количеством топиков, посчитать для каждой когерентность и выбрать ту модель, где когерентность больше.\n",
    "\n",
    "Для наглядности я решила не считать сразу максимальную когерентность в функции, а вывести график, показывающий как она меняется в зависимости от количества топиков\n",
    "\n",
    "Результат мне показался немного странным: чем меньше топиков, тем точнее модель... Возможно, где-то есть моя ошибка, но я не понимаю где\n",
    "\n",
    "Я решила не выбирать наименьшее число топиков. Для дальнейшей работы взяла 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_coherence(dictionary, corpus, texts):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for topic_number in range(5,45,5):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=id2word,num_topics=topic_number,random_state=100,update_every=1,chunksize=100,passes=10,alpha='auto',per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = best_coherence(id2word, corpus, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(5, 45, 5)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем новую модель и получаем её топики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_more_optimal = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = lda_model_more_optimal.show_topics(num_topics=10, formatted=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет основного топика для каждого текста\n",
    "\n",
    "Проходим по каждому слову, по каждой теме, по всем словам в каждом топике, если слово из текста и слово из топика совпадают, добавляем вес слова в топике в счетчик. Завершив обход, смотрим по словарю-счетчику, какая тема в данном тексте имела больший вес, добавляем эту тему в список с основными темами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_topics = []\n",
    "\n",
    "for text in data_lemmatized:\n",
    "    topics_text = {}\n",
    "    for word in text:\n",
    "        for topic in topics:\n",
    "            for w in topic[1]:\n",
    "                if w[0] == word:\n",
    "                    if topic[0] in list(topics_text.keys()):\n",
    "                        topics_text[topic[0]] += w[1]\n",
    "                    else:\n",
    "                        topics_text[topic[0]] = w[1]\n",
    "    max_v = 0\n",
    "    main_t = 0\n",
    "    for i in topics_text.keys():\n",
    "        if topics_text[i] > max_v:\n",
    "            max_v = topics_text[i]\n",
    "            main_t = i\n",
    "    main_topics.append(main_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " На основе полученных данных строим таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dataframe = {'Main topic': main_topics, 'Text': data, 'Words from text': data_lemmatized}\n",
    "\n",
    "df2 = pd.DataFrame(dict_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main topic</th>\n",
       "      <th>Text</th>\n",
       "      <th>Words from text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (wheres my thing) Subject: WHAT car is t...</td>\n",
       "      <td>[where, thing, car, nntp_poste, host, park, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>From: (Guy Kuo) Subject: SI Clock Poll - Final...</td>\n",
       "      <td>[si, poll, final, summary, final, call, si, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Thomas E Willis) Subject: PB questions....</td>\n",
       "      <td>[question, engineering, computer, network, dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Joe Green) Subject: Re: Weitek P9000 ? ...</td>\n",
       "      <td>[division, line, host, amber, write, write, ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Jonathan McDowell) Subject: Re: Shuttle...</td>\n",
       "      <td>[question, organization, smithsonian_astrophys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11309</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Jim Zisfein) Subject: Re: Migraines and...</td>\n",
       "      <td>[migraine, city, ny_bis, reply, line, cheap, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11310</td>\n",
       "      <td>7</td>\n",
       "      <td>From: Subject: Screen Death: Mac Plus/512 Line...</td>\n",
       "      <td>[problem, screen, blank, sometimes, minor, phy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11311</td>\n",
       "      <td>4</td>\n",
       "      <td>From: (Will Estes) Subject: Mounting CPU Coole...</td>\n",
       "      <td>[este, mount, case, organization, mail, group,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11312</td>\n",
       "      <td>5</td>\n",
       "      <td>From: (Steven Collins) Subject: Re: Sphere fro...</td>\n",
       "      <td>[line, nntp_poste, host, article, write, boy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11313</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Kevin J. Gunning) Subject: stolen CBR90...</td>\n",
       "      <td>[gun, steal, organization, line, distribution_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Main topic                                               Text  \\\n",
       "0               3  From: (wheres my thing) Subject: WHAT car is t...   \n",
       "1               7  From: (Guy Kuo) Subject: SI Clock Poll - Final...   \n",
       "2               3  From: (Thomas E Willis) Subject: PB questions....   \n",
       "3               3  From: (Joe Green) Subject: Re: Weitek P9000 ? ...   \n",
       "4               3  From: (Jonathan McDowell) Subject: Re: Shuttle...   \n",
       "...           ...                                                ...   \n",
       "11309           3  From: (Jim Zisfein) Subject: Re: Migraines and...   \n",
       "11310           7  From: Subject: Screen Death: Mac Plus/512 Line...   \n",
       "11311           4  From: (Will Estes) Subject: Mounting CPU Coole...   \n",
       "11312           5  From: (Steven Collins) Subject: Re: Sphere fro...   \n",
       "11313           3  From: (Kevin J. Gunning) Subject: stolen CBR90...   \n",
       "\n",
       "                                         Words from text  \n",
       "0      [where, thing, car, nntp_poste, host, park, li...  \n",
       "1      [si, poll, final, summary, final, call, si, cl...  \n",
       "2      [question, engineering, computer, network, dis...  \n",
       "3      [division, line, host, amber, write, write, ar...  \n",
       "4      [question, organization, smithsonian_astrophys...  \n",
       "...                                                  ...  \n",
       "11309  [migraine, city, ny_bis, reply, line, cheap, a...  \n",
       "11310  [problem, screen, blank, sometimes, minor, phy...  \n",
       "11311  [este, mount, case, organization, mail, group,...  \n",
       "11312  [line, nntp_poste, host, article, write, boy, ...  \n",
       "11313  [gun, steal, organization, line, distribution_...  \n",
       "\n",
       "[11314 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляем в список всю информацию из строк таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_for_groups = df2.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формируем группы\n",
    "\n",
    "Создаем слова, ключами которого будут номера тем, а в значениях будут находиться кортежи с тексами и лемматизированными словами из текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['sigma_design', 'double', 'article', 'write', 'look', 'information', 'sigma_design', 'double', 'board', 'figure', 'work', 'sure', 'also', 'much', 'would', 'cost', 'have', 'board', 'year', 'work', 'due', 'licensing', 'problem', 'technology', 'owner', 'board', 'compression', 'technology', 'be', 'write', 'memory', 'have', 'lose', 'reference', 'correct', 'be', 'wrong', 'use', 'board', 'have', 'problem', 'file', 'icon', 'lose', 'hard', 'say', 'board', 'fault', 'else', 'however', 'decompress', 'troubled', 'file', 'recompress', 'board', 'icon', 'usually', 'reappear', 'mention', 'licensing', 'problem', 'expansion', 'utility', 'expand', 'compress', 'file', 'board', 'instal', 'stac', 'product', 'seem', 'unlikely', 'hole', 'board', 'fix', 'sad', 'make', 'reluctant', 'buy', 'product', 'be', 'stinky', 's', 'competition', 'compute', 'office', 'phone', 'email'], 'From: (Stan Kerr) Subject: Re: Sigma Designs Double up?? Article-I.D.: ux1.C52u8x.B62 Organization: University of Illinois at Urbana Lines: 29 (Joseph A. Pellettiere) writes: > I am looking for any information about the Sigma Designs > double up board. All I can figure out is that it is a > hardware compression board that works with AutoDoubler, but > I am not sure about this. Also how much would one cost? Ive had the board for over a year, and it does work with Diskdoubler, but not with Autodoubler, due to a licensing problem with Stac Technologies, the owners of the boards compression technology. (Im writing this from memory; Ive lost the reference. Please correct me if Im wrong.) Using the board, Ive had problems with file icons being lost, but its hard to say whether its the boards fault or something else; however, if I decompress the troubled file and recompress it without the board, the icon usually reappears. Because of the above mentioned licensing problem, the freeware expansion utility DD Expand will not decompress a board-compressed file unless you have the board installed. Since Stac has its own product now, it seems unlikely that the holes in Autodoubler/Diskdoubler related to the board will be fixed. Which is sad, and makes me very reluctant to buy Stacs product since theyre being so stinky. (But hey, thats competition.) -- Stan Kerr Computing & Communications Services Office, U of Illinois/Urbana Phone: 217-333-5217 Email: ')\n"
     ]
    }
   ],
   "source": [
    "groups = {}\n",
    "\n",
    "for row in list_for_groups:\n",
    "    if row[0] not in list(groups.keys()):\n",
    "        groups[row[0]] = []\n",
    "    groups[row[0]].append((row[2],row[1]))\n",
    "print(groups[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции по подсчету IDF, TF  и TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(documents):\n",
    "    N = len(documents)\n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents: \n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                if word not in idfDict.keys():\n",
    "                    idfDict[word] = 0\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBagOfWords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfWords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для обработки групп\n",
    "\n",
    "В неё поступает словарь из групп и номер группы, которая должна сейчас обрабатываться. \n",
    "\n",
    "В ней мы проходим по всем текстам группы, создаем их Counter, чтобы понять сколько раз слово встречалось в своем тексте, список этих Counter (точнее словарей из них) подаём в функцию, считающую IDFs, затем идем по-очереди по всем текстам, считаем TF, TF_IDF и находим 5 слов с самым большим TF_IDF, создаем из них список.\n",
    "\n",
    "В конце  создаем кортеж из номера основного топика, самого текста и 5 ключевых слов, кортежи для каждого текста собираем в список. Этот список и возвращает функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coun_tfidf(groups, group_number):\n",
    "    group = list(groups.values())[group_number]\n",
    "    list_of_counters = []\n",
    "    final_list = []\n",
    "    for text in group:\n",
    "        list_of_counters.append(dict(Counter(text[0])))\n",
    "    idfs_group = computeIDF(list_of_counters)\n",
    "    for text in group:\n",
    "        TF = computeTF(dict(Counter(text[0])), text[0])\n",
    "        TFIDF = computeTFIDF(TF, idfs_group)\n",
    "        help_list = []\n",
    "        for i in Counter(TFIDF).most_common(5):\n",
    "            help_list.append(i[0])\n",
    "        final_tuple = (group_number, text[1], help_list)\n",
    "        final_list.append(final_tuple)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запускаем функцию для вех групп, формируем финальный список кортежей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 'From: (Stan Kerr) Subject: Re: Sigma Designs Double up?? Article-I.D.: ux1.C52u8x.B62 Organization: University of Illinois at Urbana Lines: 29 (Joseph A. Pellettiere) writes: > I am looking for any information about the Sigma Designs > double up board. All I can figure out is that it is a > hardware compression board that works with AutoDoubler, but > I am not sure about this. Also how much would one cost? Ive had the board for over a year, and it does work with Diskdoubler, but not with Autodoubler, due to a licensing problem with Stac Technologies, the owners of the boards compression technology. (Im writing this from memory; Ive lost the reference. Please correct me if Im wrong.) Using the board, Ive had problems with file icons being lost, but its hard to say whether its the boards fault or something else; however, if I decompress the troubled file and recompress it without the board, the icon usually reappears. Because of the above mentioned licensing problem, the freeware expansion utility DD Expand will not decompress a board-compressed file unless you have the board installed. Since Stac has its own product now, it seems unlikely that the holes in Autodoubler/Diskdoubler related to the board will be fixed. Which is sad, and makes me very reluctant to buy Stacs product since theyre being so stinky. (But hey, thats competition.) -- Stan Kerr Computing & Communications Services Office, U of Illinois/Urbana Phone: 217-333-5217 Email: ', ['board', 'sigma_design', 'licensing', 'double', 'lose'])\n"
     ]
    }
   ],
   "source": [
    "final_list_for_df = []\n",
    "for i in groups:\n",
    "    final_list_for_df.extend(coun_tfidf(groups, i))\n",
    "print(final_list_for_df[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из полученного списка кортежей делаем словарь, и по нему строим финальную таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_topic_number = []\n",
    "this_text = []\n",
    "key_words = []\n",
    "\n",
    "for inf in final_list_for_df:\n",
    "    main_topic_number.append(inf[0])\n",
    "    this_text.append(inf[1])\n",
    "    key_words.append(inf[2])\n",
    "\n",
    "dict_df_final = {'Main Topic': main_topic_number, \n",
    "                 'Text': this_text,\n",
    "                 'Key words': key_words}\n",
    "\n",
    "df_final = pd.DataFrame(dict_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main Topic</th>\n",
       "      <th>Text</th>\n",
       "      <th>Key words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Stan Kerr) Subject: Re: Sigma Designs D...</td>\n",
       "      <td>[board, sigma_design, licensing, double, lose]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Allen B) Subject: Re: TIFF: philosophic...</td>\n",
       "      <td>[tiff, complexity, inability, image, significa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Ann Marie Barden) Subject: X-Terminal C...</td>\n",
       "      <td>[ncd, boot, terminal, control, access]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Chris Syphers) Subject: Re: ?? DOS font...</td>\n",
       "      <td>[font, uafhp, uark, funky, hpoe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>From: (Sam Latonia) Subject: Re: Need phone nu...</td>\n",
       "      <td>[western_digital, love, crash, phone, copy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11309</td>\n",
       "      <td>9</td>\n",
       "      <td>From: (Marty Leisner 71348 ) Subject: Intraven...</td>\n",
       "      <td>[intravenous, antibiotic, give, leisner, xerox]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11310</td>\n",
       "      <td>9</td>\n",
       "      <td>From: (Tony Alicea) Subject: Re: Rosicrucian O...</td>\n",
       "      <td>[name, group, correct, rosicrucian, even]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11311</td>\n",
       "      <td>9</td>\n",
       "      <td>From: (Thyagi Morgoth NagaSiva) Subject: Re: O...</td>\n",
       "      <td>[metaphysical, love, word, true, apparently]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11312</td>\n",
       "      <td>9</td>\n",
       "      <td>From: ( ) Subject: horse breeding and saling R...</td>\n",
       "      <td>[horse, firm, class, breeding, sale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11313</td>\n",
       "      <td>9</td>\n",
       "      <td>From: (David Dodell) Subject: HICN610 Medical ...</td>\n",
       "      <td>[child, age, report, increase, program]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Main Topic                                               Text  \\\n",
       "0               3  From: (Stan Kerr) Subject: Re: Sigma Designs D...   \n",
       "1               3  From: (Allen B) Subject: Re: TIFF: philosophic...   \n",
       "2               3  From: (Ann Marie Barden) Subject: X-Terminal C...   \n",
       "3               3  From: (Chris Syphers) Subject: Re: ?? DOS font...   \n",
       "4               3  From: (Sam Latonia) Subject: Re: Need phone nu...   \n",
       "...           ...                                                ...   \n",
       "11309           9  From: (Marty Leisner 71348 ) Subject: Intraven...   \n",
       "11310           9  From: (Tony Alicea) Subject: Re: Rosicrucian O...   \n",
       "11311           9  From: (Thyagi Morgoth NagaSiva) Subject: Re: O...   \n",
       "11312           9  From: ( ) Subject: horse breeding and saling R...   \n",
       "11313           9  From: (David Dodell) Subject: HICN610 Medical ...   \n",
       "\n",
       "                                               Key words  \n",
       "0         [board, sigma_design, licensing, double, lose]  \n",
       "1      [tiff, complexity, inability, image, significa...  \n",
       "2                 [ncd, boot, terminal, control, access]  \n",
       "3                       [font, uafhp, uark, funky, hpoe]  \n",
       "4            [western_digital, love, crash, phone, copy]  \n",
       "...                                                  ...  \n",
       "11309    [intravenous, antibiotic, give, leisner, xerox]  \n",
       "11310          [name, group, correct, rosicrucian, even]  \n",
       "11311       [metaphysical, love, word, true, apparently]  \n",
       "11312               [horse, firm, class, breeding, sale]  \n",
       "11313            [child, age, report, increase, program]  \n",
       "\n",
       "[11314 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
