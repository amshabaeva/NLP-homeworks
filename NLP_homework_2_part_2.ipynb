{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjyGZ0xGpHTD"
   },
   "source": [
    "## Домашнее задание по Автоматической обработке естественного языка №2\n",
    "\n",
    "### Настя Шабаева БКЛ181\n",
    "\n",
    "#### Сравнение нескольких морфологических анализаторов\n",
    "\n",
    "### Часть 2. Английский язык\n",
    "\n",
    "## Установка всех необходимых пакетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1nhxHCQyiWDH",
    "outputId": "d6f79023-0b7b-47ae-87f8-243407e3e6ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
      "Requirement already satisfied: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (6.1.1)\n",
      "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.10)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.8)\n",
      "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.10)\n",
      "Requirement already satisfied: janome in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.91)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.7.0)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
      "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0+cu101)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.3.1)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
      "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.6.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.2)\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from flair) (5.8)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.13.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.4)\n",
      "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.9.0)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.1.1)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.10.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (2.0.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect->flair) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.16.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.7)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.0.43)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.8.1rc2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (3.0.12)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (2.2.0)\n",
      "Requirement already satisfied: overrides==3.0.0 in /usr/local/lib/python3.6/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.0.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.0->flair) (7.1.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (2020.6.20)\n"
     ]
    }
   ],
   "source": [
    "! pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "HnoGq1zxG4cM",
    "outputId": "2a579285-7660-42bc-fdd5-74b00ffc5140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datascience in /usr/local/lib/python3.6/dist-packages (0.10.6)\n",
      "Requirement already satisfied: coveralls==0.5 in /usr/local/lib/python3.6/dist-packages (from datascience) (0.5)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from datascience) (6.1.1)\n",
      "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from datascience) (1.8.5)\n",
      "Requirement already satisfied: folium==0.2.1 in /usr/local/lib/python3.6/dist-packages (from datascience) (0.2.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from datascience) (50.3.0)\n",
      "Requirement already satisfied: coverage==3.7.1 in /usr/local/lib/python3.6/dist-packages (from datascience) (3.7.1)\n",
      "Requirement already satisfied: requests>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from coveralls==0.5->datascience) (2.23.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from coveralls==0.5->datascience) (3.13)\n",
      "Requirement already satisfied: docopt>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from coveralls==0.5->datascience) (0.6.2)\n",
      "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest->datascience) (1.9.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pytest->datascience) (0.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest->datascience) (2.0.0)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest->datascience) (1.1.1)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest->datascience) (0.13.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest->datascience) (20.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->datascience) (20.2.0)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->datascience) (2.11.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from sphinx->datascience) (1.15.0)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->datascience) (2.8.0)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->datascience) (1.2.0)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->datascience) (2.6.1)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->datascience) (1.2.4)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->datascience) (2.0.0)\n",
      "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx->datascience) (0.16)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->datascience) (0.7.12)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0.0->coveralls==0.5->datascience) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0.0->coveralls==0.5->datascience) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0.0->coveralls==0.5->datascience) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=1.0.0->coveralls==0.5->datascience) (2020.6.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->datascience) (3.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->pytest->datascience) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->datascience) (1.1.1)\n",
      "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->sphinx->datascience) (2018.9)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->sphinx->datascience) (1.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install datascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "0IOXBtfwGSkI",
    "outputId": "24c8814a-aeae-4c85-bd36-1d1478b230a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "wmV9e1FVGcj9",
    "outputId": "e1e2bedd-8012-4503-830c-c8c7550ac77a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.2.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "xhgse_6idYZ6",
    "outputId": "36aeee0f-ff96-4b1f-98be-3705c7fa9fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "!python -m nltk.downloader averaged_perceptron_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Utnm9vAqKks"
   },
   "source": [
    "### Импорт всего необходимого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "18zGCCY8GdG-",
    "outputId": "6c238cdc-e12c-4c2e-908f-4786a10571ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tag import pos_tag\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.tokenization import SegtokSentenceSplitter\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 150\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UscbfNZgqS4G"
   },
   "source": [
    "### Сам текст\n",
    "\n",
    "Я постаралась добавить в него несколько слов, которые в разных контекстах могут являться примерами разных частей речи (например, human - существительное и прилагательное, reserved - прилагательное и глагол и др). Стоит отметить, что ни один из анализаторов не отметил, например, human существительным в том контексте, где я считала его существительным. Если честно, в данном случае я не уверена, в чьей разметке проблема. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "p042tJjGilCc",
    "outputId": "788282ff-3253-43d2-8857-54280d93fe31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In case of legal proceedings, these papers would only obscure the case. \n",
      "Some of the men were famous, others obscure. I hereby separate the whales from the fish. \n",
      "Elsewhere, private vehicles are rare and those that are used have separate tunnels reserved for them. \n",
      "He invited me to a fish restaurant. He was the opposite of his brother in almost every respect, being unusually shy and reserved. \n",
      "The train is going to go in the opposite direction. Tell me, are you human, or are you more than human? \n",
      "Human nature is much the same everywhere, is not it?\n",
      "And they fear nothing, and they respect nothing, the young do not. Oddly, he felt no fear.\n"
     ]
    }
   ],
   "source": [
    "eng_text = '''In case of legal proceedings, these papers would only obscure the case. \n",
    "Some of the men were famous, others obscure. I hereby separate the whales from the fish. \n",
    "Elsewhere, private vehicles are rare and those that are used have separate tunnels reserved for them. \n",
    "He invited me to a fish restaurant. He was the opposite of his brother in almost every respect, being unusually shy and reserved. \n",
    "The train is going to go in the opposite direction. Tell me, are you human, or are you more than human? \n",
    "Human nature is much the same everywhere, is not it?\n",
    "And they fear nothing, and they respect nothing, the young do not. Oddly, he felt no fear.'''\n",
    "print(eng_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYa62DdJtTQ5"
   },
   "source": [
    "## Словарь с размеченными токенами\n",
    "\n",
    "Честно говоря, я не до конца уверена в своей разметке. Для некоторых слов мне было трудно определить часть речи. Например, тегг DET я ставила довольно интуитивно, не уверена, что получилось точно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsHBoIJGiwYJ"
   },
   "outputs": [],
   "source": [
    "eng_token_dict = {1 : {'in' : 'PR'},\n",
    "                  2 : {'case' : 'NOUN'},\n",
    "                  3 : {'of' : 'PR'},\n",
    "                  4 : {'legal' : 'ADJ'},\n",
    "                  5 : {'proceeings' : 'NOUN'},\n",
    "                  6 : {'these' : 'DET'},\n",
    "                  7 : {'papers' : 'NOUN'},\n",
    "                  8 : {'would' : 'VERB'},\n",
    "                  9 : {'only' : 'ADV'},\n",
    "                  10 : {'obscure' : 'VERB'},\n",
    "                  11 : {'the' : 'DET'},\n",
    "                  12 : {'case' : 'NOUN'},\n",
    "                  13 : {'some' : 'DET'},\n",
    "                  14 : {'of' : 'PR'},\n",
    "                  15 : {'the' : 'DET'},\n",
    "                  16 : {'men' : 'NOUN'},\n",
    "                  17 : {'were' : 'VERB'},\n",
    "                  18 : {'famous' : 'ADJ'},\n",
    "                  19 : {'others' : 'PRON'},\n",
    "                  20 : {'obscure' : 'ADJ'},\n",
    "                  21 : {'i' : 'PRON'},\n",
    "                  22 : {'hereby' : 'ADV'},\n",
    "                  23 : {'separate' : 'VERB'},\n",
    "                  24 : {'the' : 'DET'},\n",
    "                  25 : {'whales' : 'NOUN'},\n",
    "                  26 : {'from' : 'PR'},\n",
    "                  27 : {'the' : 'DET'},\n",
    "                  28 : {'fish' : 'NOUN'},\n",
    "                  29 : {'elsewhere' : 'ADV'},\n",
    "                  30 : {'private' : 'ADJ'},\n",
    "                  31 : {'vehicles' : 'NOUN'},\n",
    "                  32 : {'are' : 'VERB'},\n",
    "                  33 : {'rare' : 'ADJ'},\n",
    "                  34 : {'and' : 'CCONJ'},\n",
    "                  35 : {'those' : 'PRON'},\n",
    "                  36 : {'that' : 'CCONJ'},\n",
    "                  37 : {'are' : 'VERB'},\n",
    "                  38 : {'used' : 'VERB'},\n",
    "                  39 : {'have' : 'VERB'},\n",
    "                  40 : {'separate' : 'ADJ'},\n",
    "                  41 : {'tunnels' : 'NOUN'},\n",
    "                  42 : {'reserved' : 'VERB'},\n",
    "                  43 : {'for' : 'PR'},\n",
    "                  44 : {'them' : 'PRON'},\n",
    "                  45 : {'he' : 'PRON'},\n",
    "                  46 : {'invited' : 'VERB'},\n",
    "                  47 : {'me' : 'PRON'},\n",
    "                  48 : {'to' : 'PR'},\n",
    "                  49 : {'a' : 'DET'},\n",
    "                  50 : {'fish' : 'ADJ'},\n",
    "                  51 : {'restaurant' : 'NOUN'},\n",
    "                  52 : {'he' : 'PRON'},\n",
    "                  53 : {'was' : 'VERB'},\n",
    "                  54 : {'the' : 'DET'},\n",
    "                  55 : {'opposite' : 'NOUN'},\n",
    "                  56 : {'of' : 'PR'},\n",
    "                  57 : {'his' : 'PRON'},\n",
    "                  58 : {'brother' : 'NOUN'},\n",
    "                  59 : {'in' : 'PR'},\n",
    "                  60 : {'almost' : 'ADV'},\n",
    "                  61 : {'every' : 'DET'},\n",
    "                  62 : {'respect' : 'NOUN'},\n",
    "                  63 : {'being' : 'VERB'},\n",
    "                  64 : {'unusually' : 'ADV'},\n",
    "                  65 : {'shy' : 'ADJ'},\n",
    "                  66 : {'and' : 'CCONJ'},\n",
    "                  67 : {'reserved' : 'ADJ'},\n",
    "                  68 : {'the' : 'DET'},\n",
    "                  69 : {'train' : 'NOUN'},\n",
    "                  70 : {'is' : 'VERB'},\n",
    "                  71 : {'going' : 'VERB'},\n",
    "                  72 : {'to' : 'PART'},\n",
    "                  73 : {'go' : 'VERB'},\n",
    "                  74 : {'in' : 'PR'},\n",
    "                  75 : {'the' : 'DET'},\n",
    "                  76 : {'opposite' : 'ADJ'},\n",
    "                  77 : {'direction' : 'NOUN'},\n",
    "                  78 : {'tell' : 'VERB'},\n",
    "                  79 : {'me' : 'PRON'},\n",
    "                  80 : {'are' : 'VERB'},\n",
    "                  81 : {'you' : 'PRON'},\n",
    "                  82 : {'human' : 'NOUN'},\n",
    "                  83 : {'or' : 'CCONJ'},\n",
    "                  84 : {'are' : 'VERB'},\n",
    "                  85 : {'you' : 'PRON'},\n",
    "                  86 : {'more' : 'ADV'},\n",
    "                  87 : {'than' : 'CCONJ'},\n",
    "                  88 : {'human' : 'NOUN'},\n",
    "                  89 : {'human' : 'ADJ'},\n",
    "                  90 : {'nature' : 'NOUN'},\n",
    "                  91 : {'is' : 'VERB'},\n",
    "                  92 : {'much' : 'ADV'},\n",
    "                  93 : {'the' : 'DET'},\n",
    "                  94 : {'same' : 'ADJ'},\n",
    "                  95 : {'everywhere' : 'ADV'},\n",
    "                  96 : {'is' : 'VERB'},\n",
    "                  97 : {'not' : 'PART'},\n",
    "                  98 : {'it' : 'PRON'},\n",
    "                  99 : {'and' : 'CCONJ'},\n",
    "                  100 : {'they' : 'PRON'},\n",
    "                  101 : {'fear' : 'VERB'},\n",
    "                  102 : {'nothing' : 'PRON'},\n",
    "                  103 : {'and' : 'CCONJ'},\n",
    "                  104 : {'they' : 'PRON'},\n",
    "                  105 : {'respect' : 'VERB'},\n",
    "                  106 : {'nothing' : 'PRON'},\n",
    "                  107 : {'the' : 'DET'},\n",
    "                  108 : {'young' : 'NOUN'},\n",
    "                  109 : {'do' : 'VERB'},\n",
    "                  110 : {'not' : 'PART'},\n",
    "                  111 : {'oddly' : 'ADV'},\n",
    "                  112 : {'he' : 'PRON'},\n",
    "                  113 : {'felt' : 'VERB'},\n",
    "                  114 : {'no' : 'DET'},\n",
    "                  115 : {'fear' : 'NOUN'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CX4ZtDBCuV9E"
   },
   "source": [
    "### Вынимаем из словаря список только с частеречными теггами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvfQLVBWJc8L"
   },
   "outputs": [],
   "source": [
    "real_list = []\n",
    "\n",
    "for i in eng_token_dict.values():\n",
    "    for j in i.values():\n",
    "        real_list.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AjOs07GuwJL"
   },
   "source": [
    "### Работа со SpaCy\n",
    "\n",
    "Обрабатываем текст с помощью SpaCy, потом проходим по всем частеречным теггам, меняем те названия, которые не совпали с моими. На основе полученного списка и \"реального списка\" считаем Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "2-zgeHo0zEAi",
    "outputId": "52816732-473d-4427-8c39-cc0918f84080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9217391304347826\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(eng_text)\n",
    "\n",
    "same_taggs = ['NOUN', 'VERB', 'ADV', 'ADJ', 'DET', 'PART', 'PRON', 'CCONJ']\n",
    "spacy_list = []\n",
    "\n",
    "\n",
    "for i, s in enumerate(doc.sents):\n",
    "    for t in s:\n",
    "        if t.pos_ != 'PUNCT':\n",
    "            if t.pos_ in same_taggs:\n",
    "                spacy_list.append(t.pos_)\n",
    "            else:\n",
    "                if t.pos_ == 'ADP':\n",
    "                    spacy_list.append('PR')\n",
    "                else:\n",
    "                    if t.pos_ == 'AUX':\n",
    "                        spacy_list.append('VERB')\n",
    "                    else:\n",
    "                        if t.pos_ == 'SCONJ':\n",
    "                            spacy_list.append('CCONJ')\n",
    "\n",
    "print('Accuracy: ', accuracy_score(real_list, spacy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Is2XRxXNvqc9"
   },
   "source": [
    "### Функция для переименовывания теггов, записанных в формате NLTK и flair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rd7jvqVDfr7b"
   },
   "outputs": [],
   "source": [
    "def change_tags(list_tags):\n",
    "    list_append = []\n",
    "    for i in list_tags:\n",
    "        if (i[1] == 'IN') or (i[1] == 'TO'):\n",
    "            list_append.append('PR')\n",
    "        else:\n",
    "            if (i[1] == 'NN') or (i[1] == 'NNS') or (i[1] == 'NNP') or (i[1] == 'NNPS'):\n",
    "                list_append.append('NOUN')\n",
    "            else:\n",
    "                if (i[1] == 'JJ') or (i[1] == 'JJS') or (i[1] == 'JJR'):\n",
    "                    list_append.append('ADJ')\n",
    "                else:\n",
    "                    if (i[1] == 'RB') or (i[1] == 'RBR') or (i[1] == 'RBS') or (i[1] == 'PDT') or (i[1] == 'WRB'):\n",
    "                        list_append.append('ADV')\n",
    "                    else:\n",
    "                        if i[1] == 'DT':\n",
    "                            list_append.append('DET')\n",
    "                        else:\n",
    "                            if (i[1] == 'MD') or (i[1] == 'VB') or (i[1] == 'VBD') or (i[1] == 'VBZ') or (i[1] == 'VBP') or (i[1] == 'VBG') or (i[1] == 'VBN'):\n",
    "                                list_append.append('VERB')\n",
    "                            else:\n",
    "                                if (i[1] == 'PRP') or (i[1] == 'PRP$') or (i[1] == 'WP') or (i[1] == 'WP$'):\n",
    "                                    list_append.append('PRON')\n",
    "                                else:\n",
    "                                    if (i[1] == 'WDT') or (i[1] == 'CC'):\n",
    "                                        list_append.append('CCONJ')\n",
    "                                    else:\n",
    "                                        if (i[1] == 'RP'):\n",
    "                                            list_append.append('PART')\n",
    "    return list_append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrrTGYYFwVSq"
   },
   "source": [
    "### Обработка текста в NLTK\n",
    "\n",
    "Токенизируем текст, обрабатываем в nltk.pos_tag, а дальше отправляем в функцию, меняющую имена теггов. На основе полученного списка и \"реального списка\" подсчитываем Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "1gUEHo-Dy2ZT",
    "outputId": "40384c91-244b-4c35-faca-a90a93a1052b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8608695652173913\n"
     ]
    }
   ],
   "source": [
    "nltk_list = []\n",
    "nltk_list = change_tags(nltk.pos_tag(nltk.word_tokenize(eng_text)))\n",
    "\n",
    "\n",
    "print('Accuracy: ', accuracy_score(real_list, nltk_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs7UU9n8xw5x"
   },
   "source": [
    "### Обработка с помощью flair\n",
    "\n",
    "С помощью flair текст делим на предложения, обрабатываем предложения, с помощью регулярных выражений вынимаем из них тегги.\n",
    "Дальше меняем формат списка с теггами (для функции, которая переименовывает нужно, чтобы поступал список списков, в котором тегг на 2м месте. Отправляем полученный список в функцию, которая переименовывает тегги. И на основе полученного списка и \"реального\" считаем Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "JO5vQ1DQkP0E",
    "outputId": "14b2e3ff-d8d0-4b26-e43f-ca34219779fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-16 18:20:01,711 loading file /root/.flair/models/en-pos-ontonotes-fast-v0.5.pt\n",
      "Accuracy:  0.8956521739130435\n"
     ]
    }
   ],
   "source": [
    "pos = SequenceTagger.load('pos-fast')\n",
    "splitter = SegtokSentenceSplitter()\n",
    "\n",
    "sentences = splitter.split(eng_text)\n",
    "flair_list = []\n",
    "tags = []\n",
    "tags_new = []\n",
    "help_l = []\n",
    "pos.predict(sentences)\n",
    "\n",
    "for sentence in sentences:\n",
    "    tags.extend(re.findall(r'<(.+?)>', sentence.to_tagged_string()))\n",
    "\n",
    "for i in range(len(tags)):\n",
    "    help_l = []\n",
    "    help_l.append(i)\n",
    "    help_l.append(tags[i])\n",
    "    tags_new.append(help_l)\n",
    "\n",
    "flair_list = change_tags(tags_new)\n",
    "print('Accuracy: ', accuracy_score(real_list, flair_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD_2df0w1Ixv"
   },
   "source": [
    "### Составление таблицы\n",
    "\n",
    "Создаем датафрейм с отдельными колонками для слова, тегга по моей разметке, тегга по разметке SpaCy, тегга по разметке NLTK и тегга по разметке flair.\n",
    "\n",
    "В конце выводим Accuracy для каждого анализатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "edYTbw_UkrC6",
    "outputId": "8c12aab8-66dd-4f93-adb0-797f7b8fbf0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Word my POS spacy POS nltk POS flair POS\n",
      "0            in     PR        PR       PR        PR\n",
      "1          case   NOUN      NOUN     NOUN      NOUN\n",
      "2            of     PR        PR       PR        PR\n",
      "3         legal    ADJ       ADJ      ADJ       ADJ\n",
      "4    proceeings   NOUN      NOUN     NOUN      NOUN\n",
      "5         these    DET       DET      DET       DET\n",
      "6        papers   NOUN      NOUN     NOUN      NOUN\n",
      "7         would   VERB      VERB     VERB      VERB\n",
      "8          only    ADV       ADV      ADV       ADV\n",
      "9       obscure   VERB      VERB     VERB      VERB\n",
      "10          the    DET       DET      DET       DET\n",
      "11         case   NOUN      NOUN     NOUN      NOUN\n",
      "12         some    DET       DET      DET       DET\n",
      "13           of     PR        PR       PR        PR\n",
      "14          the    DET       DET      DET       DET\n",
      "15          men   NOUN      NOUN     NOUN      NOUN\n",
      "16         were   VERB      VERB     VERB      VERB\n",
      "17       famous    ADJ       ADJ      ADJ       ADJ\n",
      "18       others   PRON      NOUN     NOUN      NOUN\n",
      "19      obscure    ADJ       ADJ     VERB       ADJ\n",
      "20            i   PRON      PRON     PRON      PRON\n",
      "21       hereby    ADV       ADV     VERB       ADV\n",
      "22     separate   VERB      VERB      ADJ      VERB\n",
      "23          the    DET       DET      DET       DET\n",
      "24       whales   NOUN      NOUN     NOUN      NOUN\n",
      "25         from     PR        PR       PR        PR\n",
      "26          the    DET       DET      DET       DET\n",
      "27         fish   NOUN      NOUN     NOUN      NOUN\n",
      "28    elsewhere    ADV       ADV      ADV       ADV\n",
      "29      private    ADJ       ADJ      ADJ       ADJ\n",
      "30     vehicles   NOUN      NOUN     NOUN      NOUN\n",
      "31          are   VERB      VERB     VERB      VERB\n",
      "32         rare    ADJ       ADJ      ADJ       ADJ\n",
      "33          and  CCONJ     CCONJ    CCONJ     CCONJ\n",
      "34        those   PRON       DET      DET       DET\n",
      "35         that  CCONJ       DET    CCONJ     CCONJ\n",
      "36          are   VERB      VERB     VERB      VERB\n",
      "37         used   VERB      VERB     VERB      VERB\n",
      "38         have   VERB      VERB     VERB      VERB\n",
      "39     separate    ADJ       ADJ      ADJ       ADJ\n",
      "40      tunnels   NOUN      NOUN     NOUN      NOUN\n",
      "41     reserved   VERB      VERB     VERB      VERB\n",
      "42          for     PR        PR       PR        PR\n",
      "43         them   PRON      PRON     PRON      PRON\n",
      "44           he   PRON      PRON     PRON      PRON\n",
      "45      invited   VERB      VERB     VERB      VERB\n",
      "46           me   PRON      PRON     PRON      PRON\n",
      "47           to     PR        PR       PR        PR\n",
      "48            a    DET       DET      DET       DET\n",
      "49         fish    ADJ      NOUN      ADJ      NOUN\n",
      "50   restaurant   NOUN      NOUN     NOUN      NOUN\n",
      "51           he   PRON      PRON     PRON      PRON\n",
      "52          was   VERB      VERB     VERB      VERB\n",
      "53          the    DET       DET      DET       DET\n",
      "54     opposite   NOUN      NOUN     NOUN      NOUN\n",
      "55           of     PR        PR       PR        PR\n",
      "56          his   PRON       DET     PRON      PRON\n",
      "57      brother   NOUN      NOUN     NOUN      NOUN\n",
      "58           in     PR        PR       PR        PR\n",
      "59       almost    ADV       ADV      ADV       ADV\n",
      "60        every    DET       DET      DET       DET\n",
      "61      respect   NOUN      NOUN     NOUN      NOUN\n",
      "62        being   VERB      VERB     VERB      VERB\n",
      "63    unusually    ADV       ADV      ADV       ADV\n",
      "64          shy    ADJ       ADJ      ADJ       ADJ\n",
      "65          and  CCONJ     CCONJ    CCONJ     CCONJ\n",
      "66     reserved    ADJ       ADJ     VERB       ADJ\n",
      "67          the    DET       DET      DET       DET\n",
      "68        train   NOUN      NOUN     NOUN      NOUN\n",
      "69           is   VERB      VERB     VERB      VERB\n",
      "70        going   VERB      VERB     VERB      VERB\n",
      "71           to   PART      PART       PR        PR\n",
      "72           go   VERB      VERB     VERB      VERB\n",
      "73           in     PR        PR       PR        PR\n",
      "74          the    DET       DET      DET       DET\n",
      "75     opposite    ADJ       ADJ      ADJ       ADJ\n",
      "76    direction   NOUN      NOUN     NOUN      NOUN\n",
      "77         tell   VERB      VERB     VERB      VERB\n",
      "78           me   PRON      PRON     PRON      PRON\n",
      "79          are   VERB      VERB     VERB      VERB\n",
      "80          you   PRON      PRON     PRON      PRON\n",
      "81        human   NOUN       ADJ      ADJ       ADJ\n",
      "82           or  CCONJ     CCONJ    CCONJ     CCONJ\n",
      "83          are   VERB      VERB     VERB      VERB\n",
      "84          you   PRON      PRON     PRON      PRON\n",
      "85         more    ADV       ADJ      ADJ       ADV\n",
      "86         than  CCONJ     CCONJ       PR        PR\n",
      "87        human   NOUN       ADJ      ADJ       ADJ\n",
      "88        human    ADJ       ADJ      ADJ       ADJ\n",
      "89       nature   NOUN      NOUN     NOUN      NOUN\n",
      "90           is   VERB      VERB     VERB      VERB\n",
      "91         much    ADV       ADV      ADV       ADV\n",
      "92          the    DET       DET      DET       DET\n",
      "93         same    ADJ       ADJ      ADJ       ADJ\n",
      "94   everywhere    ADV       ADV      ADV       ADV\n",
      "95           is   VERB      VERB     VERB      VERB\n",
      "96          not   PART      PART      ADV       ADV\n",
      "97           it   PRON      PRON     PRON      PRON\n",
      "98          and  CCONJ     CCONJ    CCONJ     CCONJ\n",
      "99         they   PRON      PRON     PRON      PRON\n",
      "100        fear   VERB      VERB     VERB      VERB\n",
      "101     nothing   PRON      PRON     NOUN      NOUN\n",
      "102         and  CCONJ     CCONJ    CCONJ     CCONJ\n",
      "103        they   PRON      PRON     PRON      PRON\n",
      "104     respect   VERB      VERB     VERB      VERB\n",
      "105     nothing   PRON      PRON     NOUN      NOUN\n",
      "106         the    DET       DET      DET       DET\n",
      "107       young   NOUN       ADJ      ADJ       ADJ\n",
      "108          do   VERB      VERB     VERB      VERB\n",
      "109         not   PART      PART      ADV       ADV\n",
      "110       oddly    ADV       ADV      ADV       ADV\n",
      "111          he   PRON      PRON     PRON      PRON\n",
      "112        felt   VERB      VERB     VERB      VERB\n",
      "113          no    DET       DET      DET       DET\n",
      "114        fear   NOUN      NOUN     NOUN      NOUN\n",
      "Accuracy spacy:  0.9217391304347826\n",
      "Accuracy nltk:  0.8608695652173913\n",
      "Accuracy flair:  0.8956521739130435\n"
     ]
    }
   ],
   "source": [
    "data = {'Word' : [], 'my POS' : [], 'spacy POS' : [], 'nltk POS' : [], 'flair POS' : []}\n",
    "\n",
    "for i in range(len(real_list)):\n",
    "    data['Word'].append(list(eng_token_dict[i+1].keys())[0])\n",
    "    data['my POS'].append(real_list[i])\n",
    "    data['spacy POS'].append(spacy_list[i])\n",
    "    data['nltk POS'].append(nltk_list[i])\n",
    "    data['flair POS'].append(flair_list[i])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "print('Accuracy spacy: ', accuracy_score(real_list, spacy_list))\n",
    "print('Accuracy nltk: ', accuracy_score(real_list, nltk_list))\n",
    "print('Accuracy flair: ', accuracy_score(real_list, flair_list))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP homework 2 part 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
